<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Dealing with Imbalanced Datasets | Josu Alonso Castanedo</title> <meta name="author" content="Josu Alonso Castanedo"> <meta name="description" content="Imbalanced datasets can lead to 99% precision and 0% predictive power, how could we then fit our models?"> <meta name="keywords" content="machine-learning, data-science, ai"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://josumsc.github.io/blog/2023/dealing-with-imbalanced-datasets/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Josu </span>Alonso Castanedo</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Dealing with Imbalanced Datasets</h1> <p class="post-meta">January 8, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/data-preparation"> <i class="fas fa-hashtag fa-sm"></i> data preparation</a>   <a href="/blog/tag/pytorch"> <i class="fas fa-hashtag fa-sm"></i> pytorch</a>   <a href="/blog/tag/python"> <i class="fas fa-hashtag fa-sm"></i> python</a>   </p> </header> <article class="post-content"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/imbalanced-datasets-01-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/imbalanced-datasets-01-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/imbalanced-datasets-01-1400.webp"></source> <img src="/assets/img/imbalanced-datasets-01.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <blockquote> <p><a href="https://github.com/josumsc/credit-card-fraud-detection" rel="external nofollow noopener" target="_blank">This repository</a> serves as an illustration of how this problem may appear in a real-world scenario and how to deal with it.</p> </blockquote> <p>Imagine the CFO of your organization comes to you complaining about how the recent uprise of e-commerce after the Covid outbreak has increased the risk of credit card fraud. As a Data Scientist, you start gathering data from the company’s financial records and start building a baseline model that can show the potential of this task. After a couple of days of work, you have a model that predicts fraudulent transactions with 99.9% precision. You run to the CFO to inform her/him of the good news but you get reprimanded as your model is deemed useless. What happened?</p> <p>The problem is that, as the dataset is highly imbalanced, you model is predicting that every one of the transactions is legit, so it’s unable to detect one single fraudulent transaction. This is a common problem in many industries, and it’s important to know how to deal with it.</p> <h2 id="what-is-an-imbalanced-dataset">What is an imbalanced dataset?</h2> <p>An imbalanced dataset is a dataset where the number of observations in one class is significantly higher than the number of observations in the other classes. In the example above, the number of fraudulent transactions is much lower than the number of legit transactions, with a proportion of 1 fraudulent transaction by at least 999 legit ones. This is a common problem in many industries, such as fraud detection, medical diagnosis, and mechanical engineering, where defective parts are much rare than correct ones.</p> <p>Imbalanced datasets cause problems in Machine Learning as models are focused on maximizing the accuracy of the ensemble of predictions. In the example above, the model will predict that every transaction is legit, and it will be right 99.9% of the time. This is a problem because the model will not able to detect any of the fraudulent transactions, proving itself useless for the task at hand.</p> <h2 id="how-to-deal-with-imbalanced-datasets">How to deal with imbalanced datasets</h2> <p>In the academic literature several methods are approached to deal with this particular problem. As with any other problem in Machine Learning, there is no such thing as a free lunch, and each method has its own pros and cons. In this post, I will cover the most common methods to deal with imbalanced datasets, and I will show how to implement them in Python.</p> <h3 id="dataset-resampling">Dataset resampling</h3> <p>One of the main ways to deal with imbalanced datasets is to directly resample them. The 2 main ways to perform this operation are Oversampling, which consists in adding more observations to the minority class, and Undersampling, which consists in removing observations from the majority class. In the example above, we could add more fraudulent transactions to the dataset, or we could remove legit transactions from the dataset.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/imbalanced-datasets-02-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/imbalanced-datasets-02-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/imbalanced-datasets-02-1400.webp"></source> <img src="/assets/img/imbalanced-datasets-02.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Although we could use random approaches to perform both over and under sampling, to perform this operations we have more advanced methods such as <a href="https://arxiv.org/abs/1106.1813" rel="external nofollow noopener" target="_blank">SMOTE</a> or <a href="https://www.sciencedirect.com/science/article/pii/S0957417422005280" rel="external nofollow noopener" target="_blank">NearMiss</a>, both based on Nearest Neighbors models, for repectively over and under sampling. These methods are implemented in the <a href="https://imbalanced-learn.org/stable/" rel="external nofollow noopener" target="_blank">imbalanced-learn</a> Python library are easy enough to implement:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">NearMiss</span>
<span class="kn">from</span> <span class="n">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>

<span class="c1"># Change between the desired resampling method
</span><span class="n">resampler</span> <span class="o">=</span> <span class="nc">NearMiss</span><span class="p">()</span>
<span class="c1"># resampler = SMOTE()
</span>
<span class="n">X_resampled</span><span class="p">,</span> <span class="n">y_resampled</span> <span class="o">=</span> <span class="n">resampler</span><span class="p">.</span><span class="nf">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div> <p>This kind of transformers work quite fine out-of-the-box, but some parameters we may want to tune are the number of neighbors to consider when resampling, and the sampling proportions. In the example above, we are using the default parameters, but we could tune them to get better results.</p> <blockquote> <p>It’s extremely important not to resample the test partition of the dataset, as we want it to be as close as possible to the real world scenario, when the classes will keep their natural imbalance.</p> </blockquote> <h3 id="metric-selection">Metric Selection</h3> <p>Another way to deal with imbalanced datasets is to select a metric that is more focused on the minority class. In the example above, we could use the <a href="https://en.wikipedia.org/wiki/F1_score" rel="external nofollow noopener" target="_blank">F1 score</a> instead of the accuracy, as it is more focused on the minority class. This way, we will be able to detect the fraudulent transactions, even if we are not able to detect all of them.</p> <p>As with many other metrics, the F1 score is implemented in the <a href="https://scikit-learn.org/stable/" rel="external nofollow noopener" target="_blank">scikit-learn</a> library:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_repeated</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                            <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.94</span><span class="p">],</span>
                            <span class="n">class_sep</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"F1 obtained: </span><span class="si">{</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s">'macro'</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <p>If we are instead using PyTorch, we can use the <a href="https://torchmetrics.readthedocs.io/en/stable/classification/f1_score.html" rel="external nofollow noopener" target="_blank">F1 score</a> implemented in the <a href="https://torchmetrics.readthedocs.io/en/latest/" rel="external nofollow noopener" target="_blank">torchmetrics</a> library:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">F1Score</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">optim</span>

<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Simple neural network with 2 hidden layers
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_repeated</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                            <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.94</span><span class="p">],</span>
                            <span class="n">class_sep</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="nf">float</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="nf">long</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Net</span><span class="p">()</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="n">f1</span> <span class="o">=</span> <span class="nc">F1Score</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s">"multiclass"</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s">'macro'</span><span class="p">)</span>

<span class="k">with</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        <span class="n">pbar</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">pbar</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">"Loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> - F1: </span><span class="si">{</span><span class="nf">f1</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"F1 obtained: </span><span class="si">{</span><span class="nf">f1</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <p>Some other useful metrics to consider here are the <a href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="external nofollow noopener" target="_blank">Precision-Recall curve</a> and the <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="external nofollow noopener" target="_blank">ROC curve</a>, so feel free to check them out while building and evaluating your models.</p> <h3 id="cost-sensitive-learning">Cost-sensitive learning</h3> <p>Another way to deal with imbalanced datasets is to use cost-sensitive learning. In this approach, we assign a cost to each class, and we use this cost to weight the loss function of the model. This way, the model will be more focused on minimizing the loss of the minority class, and it will be less focused on minimizing the loss of the majority class. This approach is implemented in the <a href="https://scikit-learn.org/stable/" rel="external nofollow noopener" target="_blank">scikit-learn</a> library with the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="external nofollow noopener" target="_blank">class_weight</a> parameter:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The code would be the same as in the previous section but with the following change
</span><span class="n">clf</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mf">0.94</span><span class="p">})</span>
</code></pre></div></div> <p>A similar implementation can take place in PyTorch with the <a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html" rel="external nofollow noopener" target="_blank">torch.nn.CrossEntropyLoss</a> class:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The code would be the same as in the previous section but with the following change
</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.94</span><span class="p">]))</span>
</code></pre></div></div> <h3 id="do-nothing">Do nothing</h3> <p>Yes! You read that right. Sometimes, the best way to deal with imbalanced datasets is to do nothing. In some cases, the model will be able to detect the minority class even if it is not able to detect all of them. With neural networks this approach has gained some popularity recently due to their predictive power, so do not be afraid to try it out.</p> <h2 id="final-remarks">Final remarks</h2> <p>Imbalanced datasets are one of the most common problems on modern applications of Machine Learning. It’s difficult to stumble upon a dataset that is perfectly balanced in a production environment. In this article, we have seen some of the most common approaches to deal with imbalance, and we have seen how to implement them in Python. The key takeaway from this article is that there is no one-size-fits-all solution to this problem. You will have to validate several approaches with the test set against imbalance robust metrics such as F1 or AUC.</p> <p>I hope that you have found this article useful, and that you will be able to use these techniques in your future projects. See you soon!</p> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"josumsc/josumsc.github.io","data-repo-id":"R_kgDOIyNXzw","data-category":"Announcements","data-category-id":"DIC_kwDOIyNXz84CTnxY","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Josu Alonso Castanedo. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>